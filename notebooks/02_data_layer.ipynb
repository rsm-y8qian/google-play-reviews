{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6faa09b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repo root: d:\\intern project\\google-play-reviews\n",
      "\n",
      "[RAW TABLES]\n",
      " - play_reviews: shape=(26880, 11)\n",
      "\n",
      "[PROCESSED TABLES]\n",
      " - reviews_enriched: shape=(26880, 13)\n",
      "\n",
      "[RELATIONAL INTEGRITY CHECKS]\n",
      "raw_rows: 26880\n",
      "raw_unique_ids: 26880\n",
      "processed_rows: 26880\n",
      "processed_unique_ids: 26880\n",
      "id_overlap: 26880\n",
      "processed_coverage_of_raw: 100.00%\n",
      "raw_duplicate_rate: 0.00%\n",
      "processed_duplicate_rate: 0.00%\n",
      "\n",
      "[BUILD ANALYSIS VIEW]\n",
      "Merged shape: (26880, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_image_url</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>thumbs_up</th>\n",
       "      <th>review_created_version</th>\n",
       "      <th>review_time</th>\n",
       "      <th>reply_text</th>\n",
       "      <th>reply_time</th>\n",
       "      <th>app_version</th>\n",
       "      <th>thumbs_up_count</th>\n",
       "      <th>reply_content</th>\n",
       "      <th>replied_at</th>\n",
       "      <th>review_len</th>\n",
       "      <th>word_count</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2876fe36-e40d-45e4-98c6-509d937232a9</td>\n",
       "      <td>Mahakal Gulshan Sharma</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>radhe radhe</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-12-29 10:43:25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f45da16f-dd83-4224-8093-d857a616afb9</td>\n",
       "      <td>Donthi Naresh</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>super</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2025.350</td>\n",
       "      <td>2025-12-29 10:41:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2025.350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6af6aec0-a07b-4ffc-8b27-5231ebf1ff23</td>\n",
       "      <td>Royrex Ndlovu</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a-/ALV-U...</td>\n",
       "      <td>ultra super app</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2025.350</td>\n",
       "      <td>2025-12-29 10:41:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2025.350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2686a432-6404-4082-82fa-cb9e1144c226</td>\n",
       "      <td>mohamed</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>It is great</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2025.350</td>\n",
       "      <td>2025-12-29 10:40:17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2025.350</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.6249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87f13bab-ce7f-4bca-9ab1-48075715b93c</td>\n",
       "      <td>Rahul Rajput</td>\n",
       "      <td>https://play-lh.googleusercontent.com/a/ACg8oc...</td>\n",
       "      <td>bhut bura aap h</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-12-29 10:40:15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              review_id               user_name  \\\n",
       "0  2876fe36-e40d-45e4-98c6-509d937232a9  Mahakal Gulshan Sharma   \n",
       "1  f45da16f-dd83-4224-8093-d857a616afb9           Donthi Naresh   \n",
       "2  6af6aec0-a07b-4ffc-8b27-5231ebf1ff23           Royrex Ndlovu   \n",
       "3  2686a432-6404-4082-82fa-cb9e1144c226                 mohamed   \n",
       "4  87f13bab-ce7f-4bca-9ab1-48075715b93c            Rahul Rajput   \n",
       "\n",
       "                                      user_image_url      review_text  rating  \\\n",
       "0  https://play-lh.googleusercontent.com/a-/ALV-U...      radhe radhe       3   \n",
       "1  https://play-lh.googleusercontent.com/a/ACg8oc...            super       5   \n",
       "2  https://play-lh.googleusercontent.com/a-/ALV-U...  ultra super app       5   \n",
       "3  https://play-lh.googleusercontent.com/a/ACg8oc...      It is great       5   \n",
       "4  https://play-lh.googleusercontent.com/a/ACg8oc...  bhut bura aap h       1   \n",
       "\n",
       "   thumbs_up review_created_version          review_time  reply_text  \\\n",
       "0          0                    NaN  2025-12-29 10:43:25         NaN   \n",
       "1          0             1.2025.350  2025-12-29 10:41:40         NaN   \n",
       "2          0             1.2025.350  2025-12-29 10:41:21         NaN   \n",
       "3          0             1.2025.350  2025-12-29 10:40:17         NaN   \n",
       "4          0                    NaN  2025-12-29 10:40:15         NaN   \n",
       "\n",
       "   reply_time app_version  thumbs_up_count  reply_content  replied_at  \\\n",
       "0         NaN         NaN                0            NaN         NaN   \n",
       "1         NaN  1.2025.350                0            NaN         NaN   \n",
       "2         NaN  1.2025.350                0            NaN         NaN   \n",
       "3         NaN  1.2025.350                0            NaN         NaN   \n",
       "4         NaN         NaN                0            NaN         NaN   \n",
       "\n",
       "   review_len  word_count  sentiment  \n",
       "0          11           2     0.0000  \n",
       "1           5           1     0.5994  \n",
       "2          15           3     0.5994  \n",
       "3          11           3     0.6249  \n",
       "4          15           4     0.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved merged dataset to: d:\\intern project\\google-play-reviews\\data\\processed\\reviews_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 02_data_layer.ipynb\n",
    "# Data Layer Construction (pandas table abstraction)\n",
    "# =========================\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from typing import Dict, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ---------- Config ----------\n",
    "RAW_FILE = \"play_reviews_ingested.csv\"\n",
    "PROCESSED_FILE = \"reviews_enriched.csv\"\n",
    "\n",
    "RAW_TABLE_NAME = \"play_reviews\"\n",
    "PROCESSED_TABLE_NAME = \"reviews_enriched\"\n",
    "\n",
    "JOIN_KEY = \"review_id\"\n",
    "\n",
    "# Optional output (set to None if you don't want to save)\n",
    "MERGED_OUTPUT_NAME = \"reviews_merged.csv\"\n",
    "\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def resolve_repo_root() -> Path:\n",
    "    \"\"\"\n",
    "    Robustly find repo root when running from:\n",
    "    - repo root\n",
    "    - notebooks/ directory\n",
    "    \"\"\"\n",
    "    cwd = Path.cwd()\n",
    "\n",
    "    # Common patterns\n",
    "    if (cwd / \"data\").exists() and (cwd / \"notebooks\").exists():\n",
    "        return cwd\n",
    "\n",
    "    if cwd.name == \"notebooks\" and (cwd.parent / \"data\").exists():\n",
    "        return cwd.parent\n",
    "\n",
    "    # Fallback: climb up a few levels looking for /data\n",
    "    cur = cwd\n",
    "    for _ in range(5):\n",
    "        if (cur / \"data\").exists():\n",
    "            return cur\n",
    "        cur = cur.parent\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate repo root containing a 'data/' directory. \"\n",
    "        \"Run this notebook from repo root or notebooks/.\"\n",
    "    )\n",
    "\n",
    "\n",
    "def assert_columns_exist(df: pd.DataFrame, required: Tuple[str, ...], table_name: str) -> None:\n",
    "    missing = [c for c in required if c not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Table '{table_name}' is missing required columns: {missing}\")\n",
    "\n",
    "\n",
    "def safe_read_csv(path: Path, table_name: str) -> pd.DataFrame:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing file for table '{table_name}': {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataLayer:\n",
    "    \"\"\"\n",
    "    Lightweight relational-style data layer using pandas tables.\n",
    "    \"\"\"\n",
    "    repo_root: Path\n",
    "    raw_dir: Path\n",
    "    processed_dir: Path\n",
    "    tables_raw: Dict[str, pd.DataFrame]\n",
    "    tables_processed: Dict[str, pd.DataFrame]\n",
    "\n",
    "    @classmethod\n",
    "    def build(cls) -> \"DataLayer\":\n",
    "        repo_root = resolve_repo_root()\n",
    "        raw_dir = repo_root / \"data\" / \"raw\"\n",
    "        processed_dir = repo_root / \"data\" / \"processed\"\n",
    "\n",
    "        # Load as explicit \"tables\"\n",
    "        raw_path = raw_dir / RAW_FILE\n",
    "        processed_path = processed_dir / PROCESSED_FILE\n",
    "\n",
    "        tables_raw = {\n",
    "            RAW_TABLE_NAME: safe_read_csv(raw_path, RAW_TABLE_NAME)\n",
    "        }\n",
    "        tables_processed = {\n",
    "            PROCESSED_TABLE_NAME: safe_read_csv(processed_path, PROCESSED_TABLE_NAME)\n",
    "        }\n",
    "\n",
    "        return cls(\n",
    "            repo_root=repo_root,\n",
    "            raw_dir=raw_dir,\n",
    "            processed_dir=processed_dir,\n",
    "            tables_raw=tables_raw,\n",
    "            tables_processed=tables_processed\n",
    "        )\n",
    "\n",
    "    def describe(self) -> None:\n",
    "        print(\"Repo root:\", self.repo_root)\n",
    "        print(\"\\n[RAW TABLES]\")\n",
    "        for name, df in self.tables_raw.items():\n",
    "            print(f\" - {name}: shape={df.shape}\")\n",
    "        print(\"\\n[PROCESSED TABLES]\")\n",
    "        for name, df in self.tables_processed.items():\n",
    "            print(f\" - {name}: shape={df.shape}\")\n",
    "\n",
    "    def integrity_checks(self, join_key: str = JOIN_KEY) -> Dict[str, float]:\n",
    "        raw = self.tables_raw[RAW_TABLE_NAME]\n",
    "        processed = self.tables_processed[PROCESSED_TABLE_NAME]\n",
    "\n",
    "        assert_columns_exist(raw, (join_key,), RAW_TABLE_NAME)\n",
    "        assert_columns_exist(processed, (join_key,), PROCESSED_TABLE_NAME)\n",
    "\n",
    "        raw_ids = raw[join_key].astype(str)\n",
    "        processed_ids = processed[join_key].astype(str)\n",
    "\n",
    "        raw_unique = raw_ids.nunique(dropna=True)\n",
    "        processed_unique = processed_ids.nunique(dropna=True)\n",
    "\n",
    "        overlap = len(set(raw_ids.dropna()) & set(processed_ids.dropna()))\n",
    "        coverage = overlap / raw_unique if raw_unique else 0.0\n",
    "\n",
    "        # Duplicates\n",
    "        raw_dup_rate = 1 - (raw_unique / len(raw_ids)) if len(raw_ids) else 0.0\n",
    "        processed_dup_rate = 1 - (processed_unique / len(processed_ids)) if len(processed_ids) else 0.0\n",
    "\n",
    "        results = {\n",
    "            \"raw_rows\": float(len(raw_ids)),\n",
    "            \"raw_unique_ids\": float(raw_unique),\n",
    "            \"processed_rows\": float(len(processed_ids)),\n",
    "            \"processed_unique_ids\": float(processed_unique),\n",
    "            \"id_overlap\": float(overlap),\n",
    "            \"processed_coverage_of_raw\": float(coverage),\n",
    "            \"raw_duplicate_rate\": float(raw_dup_rate),\n",
    "            \"processed_duplicate_rate\": float(processed_dup_rate),\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def build_analysis_view(\n",
    "        self,\n",
    "        join_key: str = JOIN_KEY,\n",
    "        processed_keep_cols: Optional[list] = None\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Create an analysis-ready merged dataframe (like a SQL view).\n",
    "        \"\"\"\n",
    "        raw = self.tables_raw[RAW_TABLE_NAME].copy()\n",
    "        processed = self.tables_processed[PROCESSED_TABLE_NAME].copy()\n",
    "\n",
    "        assert_columns_exist(raw, (join_key,), RAW_TABLE_NAME)\n",
    "        assert_columns_exist(processed, (join_key,), PROCESSED_TABLE_NAME)\n",
    "\n",
    "        # normalize join key to string to avoid dtype mismatch\n",
    "        raw[join_key] = raw[join_key].astype(str)\n",
    "        processed[join_key] = processed[join_key].astype(str)\n",
    "\n",
    "        # choose columns from processed to avoid duplicate columns explosion\n",
    "        if processed_keep_cols is None:\n",
    "            # Default: keep everything except columns that definitely exist in raw (excluding join_key)\n",
    "            raw_cols = set(raw.columns)\n",
    "            keep = [c for c in processed.columns if (c == join_key) or (c not in raw_cols)]\n",
    "            processed_keep_cols = keep\n",
    "\n",
    "        merged = raw.merge(\n",
    "            processed[processed_keep_cols],\n",
    "            on=join_key,\n",
    "            how=\"left\"\n",
    "        )\n",
    "\n",
    "        return merged\n",
    "\n",
    "    def save_merged(self, merged: pd.DataFrame, filename: str = MERGED_OUTPUT_NAME) -> Optional[Path]:\n",
    "        if not filename:\n",
    "            return None\n",
    "        out_path = self.processed_dir / filename\n",
    "        merged.to_csv(out_path, index=False)\n",
    "        return out_path\n",
    "\n",
    "\n",
    "# ---------- Run the data layer ----------\n",
    "dl = DataLayer.build()\n",
    "dl.describe()\n",
    "\n",
    "print(\"\\n[RELATIONAL INTEGRITY CHECKS]\")\n",
    "checks = dl.integrity_checks()\n",
    "for k, v in checks.items():\n",
    "    if \"rate\" in k or \"coverage\" in k:\n",
    "        print(f\"{k}: {v:.2%}\")\n",
    "    else:\n",
    "        print(f\"{k}: {int(v)}\")\n",
    "\n",
    "print(\"\\n[BUILD ANALYSIS VIEW]\")\n",
    "# You can customize keep columns here if you want only a few from processed:\n",
    "# processed_keep_cols = [\"review_id\", \"sentiment_label\", \"sentiment_score\", \"language\", \"review_len\"]\n",
    "merged = dl.build_analysis_view()\n",
    "\n",
    "print(\"Merged shape:\", merged.shape)\n",
    "display(merged.head(5))\n",
    "\n",
    "# ---------- Optional: save merged ----------\n",
    "out_path = dl.save_merged(merged)\n",
    "print(\"\\nSaved merged dataset to:\", out_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
